{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the Quora Question Paraphrase (QQP) Dataset\n",
    " \n",
    "Download and extract the QQP dataset from https://gluebenchmark.com/task \n",
    "\n",
    "You should have the following files QQP/train.tsv, QQP/test.tsv, QQP/dev.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "assert os.path.exists('QQP/train.tsv') and os.path.exists('QQP/test.tsv') and os.path.exists('QQP/dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "import spacy\n",
    "import re\n",
    "import random\n",
    "from random import shuffle\n",
    "import codecs\n",
    "import numpy as np\n",
    "from tasks import QQPTask\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME2INFO = {'qqp': (QQPTask, 'QQP')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(name,max_seq_len):\n",
    "    \n",
    "    task = NAME2INFO[name][0](NAME2INFO[name][1], max_seq_len, name)\n",
    "    train_data = task.train_data_text\n",
    "    \n",
    "    train = list(zip(train_data[0],train_data[1],train_data[2]))\n",
    "    total_len = len(train)\n",
    "    val_len = int(total_len*0.1)\n",
    "\n",
    "    val = list(zip(*train[:val_len]))\n",
    "    train = list(zip(*train[val_len:]))\n",
    "    test = task.val_data_text\n",
    "\n",
    "    print (\"Train datapoints\",len(train[0]))\n",
    "    print (\"Test datapoints\",len(test[0]))\n",
    "    print (\"Val datapoints\",len(val[0]))\n",
    "\n",
    "    df_paragraphs = list(train[1]) + list(test[1]) + list(val[1])\n",
    "    df_questions = list(train[0]) + list(test[0]) + list(val[0])\n",
    "    df_answers = list(train[2]) + list(test[2]) + list(val[2])\n",
    "    df_exp_splits = ['train']*len(train[0]) + ['test']*len(test[0]) + ['dev']*len(val[0])\n",
    "        \n",
    "    entity_list = [str(i) for i in np.unique(np.array(df_answers))]\n",
    "    f = open('{}/entity_list.txt'.format(NAME2INFO[name][1]), 'w')\n",
    "    f.write(\"\\n\".join(entity_list))\n",
    "    f.close()\n",
    "    df = {'paragraph' : df_paragraphs, 'question' : df_questions, 'answer' : df_answers, 'exp_split' : df_exp_splits}\n",
    "    df = pd.DataFrame(df)\n",
    "    df = df.dropna()\n",
    "    df.to_csv('{}/{}_dataset.csv'.format(NAME2INFO[name][1],name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train datapoints 327462\n",
      "Test datapoints 40430\n",
      "Val datapoints 36384\n"
     ]
    }
   ],
   "source": [
    "name=\"qqp\"\n",
    "max_seq_len=40\n",
    "preprocess(name,max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size :  26364\n",
      "entity2index {'0': 0, '1': 1}\n",
      "Found 25309 words in model out of 26364\n"
     ]
    }
   ],
   "source": [
    "data_file = '{}/{}_dataset.csv'.format(NAME2INFO[name][1],name)\n",
    "output_file = 'vec_{}.p'.format(name)\n",
    "answers_file = '{}/entity_list.txt'.format(NAME2INFO[name][1])\n",
    "\n",
    "# %run \"../preprocess_data_QA.py\" --data_file $data_file --output_file $output_file --all_answers_file $answers_file --word_vectors_type glove.840B.300d --min_df 10\n",
    "%run \"../preprocess_data_QA.py\" --data_file $data_file --output_file $output_file --all_answers_file $answers_file --word_vectors_type glove.840B.300d --min_df 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
